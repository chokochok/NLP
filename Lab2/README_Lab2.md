
# Lab2 ‚Äì Fine-Tuning BERT and LLaMA Classifiers

–¶–µ–π –ø—Ä–æ—î–∫—Ç —î —á–∞—Å—Ç–∏–Ω–æ—é –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó —Ä–æ–±–æ—Ç–∏ –∑ –æ–±—Ä–æ–±–∫–∏ –ø—Ä–∏—Ä–æ–¥–Ω–æ—ó –º–æ–≤–∏, –≤ —è–∫—ñ–π —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ fine-tuning –º–æ–¥–µ–ª–µ–π BERT —Ç–∞ LLaMA –¥–ª—è –∑–∞–¥–∞—á—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–µ–∫—Å—Ç—É. –†–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–æ—é —Ç–æ—á–∫–æ—é –¥–ª—è –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—è –≤–∏—Å—Ç—É–ø–∞—î STEAM baseline –º–æ–¥–µ–ª—å.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–æ—É—Ç–±—É–∫—ñ–≤

### üî∑ `Lab2_bert.ipynb`
1. **Imports** ‚Äì —ñ–º–ø–æ—Ä—Ç –±—ñ–±–ª—ñ–æ—Ç–µ–∫ (Hugging Face, PyTorch, sklearn).
2. **Load Model** ‚Äì –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è BERT-–º–æ–¥–µ–ª—ñ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó.
3. **Zero eval** ‚Äì –±–∞–∑–æ–≤–∞ –æ—Ü—ñ–Ω–∫–∞ –¥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
4. **Fine tune model** ‚Äì –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –ª–æ–≥—É–≤–∞–Ω–Ω—è–º –¥–æ `wandb`.
5. **Final eval** ‚Äì –ø—ñ–¥—Å—É–º–∫–æ–≤–∞ –æ—Ü—ñ–Ω–∫–∞ –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ–º—É –Ω–∞–±–æ—Ä—ñ.
![screenshot](Lab2/wand_bert/Pasted image.png)
![screenshot](Lab2/wand_bert/Pasted image (2).png)

### üî∑ `Lab2_llama.ipynb`
1. **Setup and Installation** ‚Äì —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ, –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ (`transformers`, `trl`, `peft`).
2. **Load the Language Model** ‚Äì –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è LLaMA-–º–æ–¥–µ–ª—ñ (—á–µ—Ä–µ–∑ `AutoModelForCausalLM`).
3. **Apply PEFT** ‚Äì –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–æ-–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è (LoRA).
4. **Prepare the Dataset** ‚Äì –æ–±—Ä–æ–±–∫–∞ —Ç–∞ —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö.
5. **Inference with Streaming (pre-training)** ‚Äì –æ—Ü—ñ–Ω–∫–∞ –¥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
6. **Configure the DPO Trainer** ‚Äì –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Direct Preference Optimization.
7. **Start Training** ‚Äì –∑–∞–ø—É—Å–∫ fine-tuning —ñ–∑ –ª–æ–≥—É–≤–∞–Ω–Ω—è–º –Ω–∞ wandb.
8. **Save the Model Locally** ‚Äì –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ.
9. **Load Saved Model** ‚Äì –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ.
10. **Inference with Streaming (post-training)** ‚Äì —Ñ—ñ–Ω–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞.
![screenshot](Lab2/wand_llama/Pasted image.png)
![screenshot](Lab2/wand_llama/Pasted image (2).png)
![screenshot](Lab2/wand_llama/Pasted image (3).png)

### üî∑ `Lab2_steam.ipynb`
- –ú—ñ—Å—Ç–∏—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—É –º–æ–¥–µ–ª—å STEAM, —è–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –∑ fine-tuned –≤–µ—Ä—Å—ñ—è–º–∏ BERT —Ç–∞ LLaMA.

## üß™ –¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó

- Transformers (Hugging Face)
- PEFT + LoRA
- TRL (Transformer Reinforcement Learning)
- PyTorch
- Weights & Biases (wandb)
- Datasets
- CUDA (–ø—Ä–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ)

## üìä –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

- –ü—Ä–æ–º—ñ–∂–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –ª–æ–≥—É—é—Ç—å—Å—è —É **Weights & Biases**.
- –î–æ–¥–∞–Ω–æ —Å–∫—Ä—ñ–Ω—à–æ—Ç–∏ –∑ `wandb` —É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π (`training_curve.png`, `eval_metrics.png`, —Ç–æ—â–æ).

## üìà –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π

| –ú–æ–¥–µ–ª—å      | –î–æ –Ω–∞–≤—á–∞–Ω–Ω—è (zero-shot) | –ü—ñ—Å–ª—è fine-tuning | –ö–æ–º–µ–Ω—Ç–∞—Ä                        |
|-------------|-------------------------|--------------------|--------------------------------|
| STREAM      | 0.84                    | -                  | –ë–∞–∑–æ–≤–∞ –º–æ–¥–µ–ª—å                  |
| BERT        | 0.36                    | 0.56               | –ö–ª–∞—Å–∏—á–Ω–∏–π fine-tune            |
| LLaMA 3.2-1B| 0.42                    | 0.68               | DPO + LoRA, –∫—Ä–∞—â–∞ –≥–µ–Ω–µ—Ä–∞–ª—ñ–∑–∞—Ü—ñ—è|

---

_–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞ —Ä–æ–±–æ—Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–∞ —É –º–µ–∂–∞—Ö –∫—É—Ä—Å—É –∑ –æ–±—Ä–æ–±–∫–∏ –ø—Ä–∏—Ä–æ–¥–Ω–æ—ó –º–æ–≤–∏._
